C:\VulnerabilityResearch\FileSet\Vulnerable\addressbook_family.inc

Current issue:
When training, X has 514 features. Starts w/ 518, removeFeatures removes 4
When feeding in a file, X has 516 features. starts w/ 518, removeFeatures removes 2

Might just need to retrain w/o removeFeatures function

test w/ naive bayes first

1. Commented out removefeatures functions



Figure out why vehicles, drivers is in one, but not the other. 
Might have to do with using fit_transform or stopWordsList in useBagOfWords_tfidf in bagOfWords
Might be because we are saving vectorizer.vocabulary_ instead of vectorizer.get_feature_names()



A big issue is that when using getFeatureColumns() in main.py, the getAllRowHeaders() function uses 
normal getCSVDirectory() instead of getCSVDirectory(True). 
This results in wrong set of headers, since it is looking at fileInfo.csv instead of inputFileInfo.csv
However, the headers shouldn't be different in the first place.
May be due to use of fit_transform

figured out that the vocabulary_ used was from only the collected file set, not the hybrid. Fixed that.

IMPORTANT
Classifier is overfitting to Juliet files. It performs fine on Juliet files,
but marks all collected files as vulnerable.