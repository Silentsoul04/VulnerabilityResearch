{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keeve\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn import metrics\n",
    "import csvWrite\n",
    "\n",
    "#do plotting inline\n",
    "%matplotlib inline\n",
    "\n",
    "#get directory\n",
    "csvDirectory = csvWrite.getCSVDirectory()\n",
    "\n",
    "data_frame = pd.read_csv(csvDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_col_names = csvWrite.getRowHeaders()\n",
    "feature_col_names = feature_col_names[2:] #all except name and vulnerable column\n",
    "predicted_class_names = ['Vulnerable']\n",
    "\n",
    "X = data_frame[feature_col_names].values # predictor feature columns (17 x m)\n",
    "y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false)(1 x m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(modelType):\n",
    "    #modelType is a string for the model being used\n",
    "    \n",
    "    # prepare the k-fold cross-validation configuration\n",
    "    n_folds = 10\n",
    "    kfold = KFold(n_folds, True, 1) #n_splits, random_state, shuffle\n",
    "\n",
    "    # cross validation estimation of performance\n",
    "    scores, precisions, recalls, f1_scores, members = list(), list(), list(), list(), list()\n",
    "\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        # select samples\n",
    "        trainX, trainy = X[train_ix], y[train_ix]\n",
    "        testX, testy = X[test_ix], y[test_ix]\n",
    "        # evaluate model\n",
    "        model, test_acc, precision, recall, f1_score = (0, 0, 0, 0, 0)\n",
    "        \n",
    "        if modelType == \"nb\":\n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_nb(trainX, trainy, testX, testy)\n",
    "        elif modelType == \"rf\":\n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_rf(trainX, trainy, testX, testy)\n",
    "        elif modelType == \"lr\":\n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_lr(trainX, trainy, testX, testy)\n",
    "        elif modelType == \"mlp\":\n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_mlp(trainX, trainy, testX, testy)\n",
    "        #print('Accuracy >%.3f' % test_acc)\n",
    "        #print('Precision >%.3f' % precision)\n",
    "        #print('Recall >%.3f' % recall)\n",
    "        #print('F1-Scores >%.3f' % f1_score)\n",
    "        scores.append(test_acc)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "        members.append(model)\n",
    "\n",
    "    # summarize expected performance\n",
    "    print('Estimated Accuracy: %.3f, Std Ddv: (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "    print('Estimated Precision: %.3f, Std Ddv: (%.3f)' % (np.mean(precisions), np.std(precisions)))\n",
    "    print('Estimated Recall: %.3f, Std Ddv: (%.3f)' % (np.mean(recalls), np.std(recalls)))\n",
    "    print('Estimated F1-Score: %.3f, Std Ddv: (%.3f)' % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_nb(X_train, y_train, X_test, y_test):\n",
    "    # define model\n",
    "    #create Gaussian Naive Bayes model object and train it with the data\n",
    "    model = GaussianNB()\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(X_test)\n",
    "\n",
    "    #Accuracy\n",
    "    test_acc = metrics.accuracy_score(y_test, predict_test)\n",
    "    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)\n",
    "    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 10 Fold Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance\n",
      "Estimated Accuracy: 0.902, Std Ddv: (0.010)\n",
      "Estimated Precision: 0.857, Std Ddv: (0.143)\n",
      "Estimated Recall: 0.136, Std Ddv: (0.036)\n",
      "Estimated F1-Score: 0.230, Std Ddv: (0.046)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(\"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_rf(X_train, y_train, X_test, y_test):\n",
    "    # define model\n",
    "    #create Random Classifier model object and train it with the data\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(X_test)\n",
    "\n",
    "    #Accuracy\n",
    "    test_acc = metrics.accuracy_score(y_test, predict_test)\n",
    "    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)\n",
    "    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 10 Fold Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance\n",
      "Estimated Accuracy: 0.902, Std Ddv: (0.010)\n",
      "Estimated Precision: 0.694, Std Ddv: (0.165)\n",
      "Estimated Recall: 0.242, Std Ddv: (0.091)\n",
      "Estimated F1-Score: 0.338, Std Ddv: (0.083)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(\"rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_lr(X_train, y_train, X_test, y_test):\n",
    "    # define model\n",
    "    #create Logistic Regression model object and train it with the data\n",
    "    model = LogisticRegression(C=0.7, random_state=42) #C is regularization hyperparameter\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(X_test)\n",
    "\n",
    "    #Accuracy\n",
    "    test_acc = metrics.accuracy_score(y_test, predict_test)\n",
    "    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)\n",
    "    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance\n",
      "Estimated Accuracy: 0.904, Std Ddv: (0.011)\n",
      "Estimated Precision: 0.927, Std Ddv: (0.047)\n",
      "Estimated Recall: 0.125, Std Ddv: (0.028)\n",
      "Estimated F1-Score: 0.219, Std Ddv: (0.044)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(\"lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide Training Data for Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame[feature_col_names].values # predictor feature columns (17 x m)\n",
    "y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false)(1 x m)\n",
    "#get a nonvulnerable column for y labels\n",
    "y_flipped = np.array(y, copy=True)\n",
    "for i in range(len(y_flipped)):\n",
    "    if y_flipped[i][0] == 0:\n",
    "        y_flipped[i][0] = 1\n",
    "    elif y_flipped[i][0] == 1:\n",
    "        y_flipped[i][0] = 0\n",
    "        \n",
    "y = np.concatenate((y_flipped, y), axis=1) #0: nonvulner, 1: vulner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_mlp(X_train, y_train, X_test, y_test):\n",
    "    # define model\n",
    "    #create MLP model object and train it with the data\n",
    "    model = keras.Sequential([\n",
    "    #start with layer of input shape (anything, 17)\n",
    "    keras.layers.Dense(500, input_shape=(csvWrite.getNumFeatures(),), activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.sigmoid) #keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    # fit model\n",
    "    history = model.fit(X_train, y_train, epochs=5)\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(X_test)\n",
    "\n",
    "    predicted = np.argmax(prediction_test, axis=1)\n",
    "    \n",
    "    #import the performance metrics library\n",
    "    report = metrics.classification_report(np.argmax(y_test, axis=1), predict_test)\n",
    "    #Accuracy\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    precision = metrics.precision_score(np.argmax(y_test, axis=1), predict_test, pos_label = 1)\n",
    "    recall = metrics.recall_score(np.argmax(y_test, axis=1), predict_test, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(np.argmax(y_test, axis=1), predict_test, pos_label = 1)\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
