{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn import metrics\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import csvWrite\n",
    "\n",
    "#do plotting inline\n",
    "%matplotlib inline\n",
    "\n",
    "#get directory\n",
    "csvDirectory = csvWrite.getCSVDirectory()\n",
    "\n",
    "data_frame = pd.read_csv(csvDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_col_names = csvWrite.getRowHeaders()\n",
    "feature_col_names = csvWrite.getAllRowHeaders()\n",
    "feature_col_names = feature_col_names[2:] #all except name and vulnerable column\n",
    "predicted_class_names = ['Vulnerable']\n",
    "\n",
    "X = data_frame[feature_col_names].values # predictor feature columns (17 x m)\n",
    "y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false)(1 x m)\n",
    "\n",
    "#get a nonvulnerable column for y labels\n",
    "y_flipped = np.array(y, copy=True)\n",
    "for i in range(len(y_flipped)):\n",
    "    if y_flipped[i][0] == 0:\n",
    "        y_flipped[i][0] = 1\n",
    "    elif y_flipped[i][0] == 1:\n",
    "        y_flipped[i][0] = 0\n",
    "        \n",
    "y = np.concatenate((y_flipped, y), axis=1) #0: nonvulner, 1: vulner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(modelType):\n",
    "    #modelType is a string for the model being used\n",
    "    \n",
    "    # prepare the k-fold cross-validation configuration\n",
    "    n_folds = 10\n",
    "    kfold = KFold(n_folds, True, 1) #n_splits, random_state, shuffle\n",
    "\n",
    "    # cross validation estimation of performance\n",
    "    scores, precisions, recalls, f1_scores, members = list(), list(), list(), list(), list()\n",
    "\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        print(\"Current cross validation iteration:\", train_ix)\n",
    "        \n",
    "        # select samples\n",
    "        trainX, trainy = X[train_ix], y[train_ix]\n",
    "        testX, testy = X[test_ix], y[test_ix]\n",
    "        # evaluate model\n",
    "        model, test_acc, precision, recall, f1_score = (0, 0, 0, 0, 0)\n",
    "        \n",
    "        print(trainX.shape[0], 1, trainX.shape[1])\n",
    "        \n",
    "        if modelType == \"lstm\":\n",
    "            # reshape input to be [samples, time steps, features]\n",
    "            trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "            testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "            \n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_lstm(trainX, trainy, testX, testy)\n",
    "        \n",
    "        scores.append(test_acc)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "        members.append(model)\n",
    "\n",
    "    # summarize expected performance\n",
    "    print(modelType, \"Performance\")\n",
    "    print('Estimated Accuracy: %.3f, Std Ddv: (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "    print('Estimated Precision: %.3f, Std Ddv: (%.3f)' % (np.mean(precisions), np.std(precisions)))\n",
    "    print('Estimated Recall: %.3f, Std Ddv: (%.3f)' % (np.mean(recalls), np.std(recalls)))\n",
    "    print('Estimated F1-Score: %.3f, Std Ddv: (%.3f)' % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_lstm(trainX, trainy, testX, testy):\n",
    "    dataDimensions = csvWrite.getNumFeatures()\n",
    "    \n",
    "    # create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(1, dataDimensions)))\n",
    "    model.add(Dense(2)) #output layer, vulner or nonvulner\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainy, epochs=5, batch_size=1, verbose=2)\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(testX)\n",
    "    \n",
    "    predicted = np.argmax(predict_test, axis=1)\n",
    "\n",
    "    #metrics\n",
    "    report = metrics.classification_report(np.argmax(testy, axis=1), predicted)\n",
    "    #test_loss, test_acc = model.evaluate(testX, testy)\n",
    "    test_acc = metrics.accuracy_score(np.argmax(testy, axis=1), predicted)\n",
    "    precision = metrics.precision_score(np.argmax(testy, axis=1), predicted, pos_label = 1)\n",
    "    recall = metrics.recall_score(np.argmax(testy, axis=1), predicted, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(np.argmax(testy, axis=1), predicted, pos_label = 1)\n",
    "    \n",
    "    '''#Accuracy\n",
    "    test_acc = metrics.accuracy_score(testy, predict_test)\n",
    "    precision = metrics.precision_score(testy, predict_test, pos_label = 1)\n",
    "    recall = metrics.recall_score(testy, predict_test, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(testy, predict_test, pos_label = 1)'''\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8738 1 518\n",
      "Epoch 1/5\n",
      " - 11s - loss: 0.0191\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.0015\n",
      "Epoch 3/5\n",
      " - 11s - loss: 9.5745e-04\n",
      "Epoch 4/5\n",
      " - 11s - loss: 6.9745e-04\n",
      "Epoch 5/5\n",
      " - 11s - loss: 5.4226e-04\n",
      "8738 1 518\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.0229\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.0017\n",
      "Epoch 3/5\n",
      " - 11s - loss: 8.8147e-04\n",
      "Epoch 4/5\n",
      " - 12s - loss: 6.4471e-04\n",
      "Epoch 5/5\n",
      " - 12s - loss: 5.1317e-04\n",
      "8738 1 518\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.0212\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.0017\n",
      "Epoch 3/5\n",
      " - 12s - loss: 9.4131e-04\n",
      "Epoch 4/5\n",
      " - 12s - loss: 8.0068e-04\n",
      "Epoch 5/5\n",
      " - 12s - loss: 5.9948e-04\n",
      "8738 1 518\n",
      "Epoch 1/5\n",
      " - 13s - loss: 0.0207\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.0015\n",
      "Epoch 3/5\n",
      " - 12s - loss: 8.8109e-04\n",
      "Epoch 4/5\n",
      " - 12s - loss: 7.0880e-04\n",
      "Epoch 5/5\n",
      " - 13s - loss: 6.0413e-04\n",
      "8738 1 518\n",
      "Epoch 1/5\n",
      " - 13s - loss: 0.0195\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.0016\n",
      "Epoch 3/5\n",
      " - 12s - loss: 8.7565e-04\n",
      "Epoch 4/5\n",
      " - 12s - loss: 6.3225e-04\n",
      "Epoch 5/5\n",
      " - 12s - loss: 5.6819e-04\n",
      "8738 1 518\n",
      "Epoch 1/5\n",
      " - 13s - loss: 0.0200\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.0018\n",
      "Epoch 3/5\n",
      " - 12s - loss: 9.2331e-04\n",
      "Epoch 4/5\n",
      " - 12s - loss: 8.1559e-04\n",
      "Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "cross_validation(\"lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
