import fileRetriever
from sklearn.feature_extraction.text import CountVectorizer

#get file set
print("Choose file set. 0: collected, 1: juliet, 2: hybrid")
fileSetChoice = int(input())
files = fileRetriever.getFileSet(fileSetChoice)

#for file in files:
#    print(file.name)

textList = [] #list of text for all files
'''for file in files:
    with open(file.dir, "r") as f:
        lines = list(f) # store all lines together
        text = "".join(lines) # join lines into single string
        textList.append(text)'''

#just testing with just two files for now
with open(files[0].dir, "r") as f:
    lines = list(f) # store all lines together
    text = "".join(lines) # join lines into single string
    #print(text)
    textList.append(text)

with open(files[1].dir, "r") as f:
    lines = list(f) # store all lines together
    text = "".join(lines) # join lines into single string
    #print(text)
    textList.append(text)

#print(textList)

#initialize vectorizer
vectorizer = CountVectorizer()
print(vectorizer)

X = vectorizer.fit_transform(textList) #tokenize and count words
print(X)

print(vectorizer.get_feature_names())
print(X.toarray())

#tutorial at https://scikit-learn.org/stable/modules/feature_extraction.html
#suggests bigram vectors to group words together, but I think we can skip this

#
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer2 = TfidfVectorizer()
X2 = vectorizer2.fit_transform(textList) #tokenize and count words
print(X2.toarray())

def getBagOfWords(fileSetChoice):
    files = fileRetriever.getFileSet(fileSetChoice)
    textList = [] #list of text for all files
    for file in files:
        with open(file.dir, "r") as f:
            lines = list(f) # store all lines together
            text = "".join(lines) # join lines into single string
            textList.append(text)

    #initialize vectorizer
    vectorizer = CountVectorizer()
    X = vectorizer.fit_transform(textList) #tokenize and count words
    print(X.toarray())
    return X.toarray()

getBagOfWords(int(0))
