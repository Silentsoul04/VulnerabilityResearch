{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import csvWrite\n",
    "\n",
    "#do plotting inline\n",
    "%matplotlib inline\n",
    "\n",
    "#get directory\n",
    "csvDirectory = csvWrite.getCSVDirectory()\n",
    "\n",
    "data_frame = pd.read_csv(csvDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_names = csvWrite.getRowHeaders()\n",
    "feature_col_names = feature_col_names[2:] #all except name and vulnerable column\n",
    "predicted_class_names = ['Vulnerable']\n",
    "\n",
    "X = data_frame[feature_col_names].values # predictor feature columns (17 x m)\n",
    "y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false)(1 x m)\n",
    "\n",
    "#get a nonvulnerable column for y labels\n",
    "y_flipped = np.array(y, copy=True)\n",
    "for i in range(len(y_flipped)):\n",
    "    if y_flipped[i][0] == 0:\n",
    "        y_flipped[i][0] = 1\n",
    "    elif y_flipped[i][0] == 1:\n",
    "        y_flipped[i][0] = 0\n",
    "        \n",
    "y = np.concatenate((y_flipped, y), axis=1) #0: nonvulner, 1: vulner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(modelType):\n",
    "    #modelType is a string for the model being used\n",
    "    \n",
    "    # prepare the k-fold cross-validation configuration\n",
    "    n_folds = 10\n",
    "    kfold = KFold(n_folds, True, 1) #n_splits, random_state, shuffle\n",
    "\n",
    "    # cross validation estimation of performance\n",
    "    scores, precisions, recalls, f1_scores, members = list(), list(), list(), list(), list()\n",
    "\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        # select samples\n",
    "        trainX, trainy = X[train_ix], y[train_ix]\n",
    "        testX, testy = X[test_ix], y[test_ix]\n",
    "        # evaluate model\n",
    "        model, test_acc, precision, recall, f1_score = (0, 0, 0, 0, 0)\n",
    "        \n",
    "        if modelType == \"rnn\":\n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_rnn(trainX, trainy, testX, testy)\n",
    "        #print('Accuracy >%.3f' % test_acc)\n",
    "        #print('Precision >%.3f' % precision)\n",
    "        #print('Recall >%.3f' % recall)\n",
    "        #print('F1-Scores >%.3f' % f1_score)\n",
    "        scores.append(test_acc)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "        members.append(model)\n",
    "\n",
    "    # summarize expected performance\n",
    "    print(modelType, \"Performance\")\n",
    "    print('Estimated Accuracy: %.3f, Std Ddv: (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "    print('Estimated Precision: %.3f, Std Ddv: (%.3f)' % (np.mean(precisions), np.std(precisions)))\n",
    "    print('Estimated Recall: %.3f, Std Ddv: (%.3f)' % (np.mean(recalls), np.std(recalls)))\n",
    "    print('Estimated F1-Score: %.3f, Std Ddv: (%.3f)' % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_rnn(X_train, y_train, X_test, y_test):\n",
    "    numFeatures = csvWrite.getNumFeatures()\n",
    "    embedding_dim = 10 #embedding dimension\n",
    "    rnn_units = 1024 #num rnn units\n",
    "    batch_size = 64\n",
    "    import functools\n",
    "    rnn = functools.partial(\n",
    "        tf.keras.layers.GRU, recurrent_activation='sigmoid')\n",
    "    # define model\n",
    "    #create MLP model object and train it with the data\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Embedding(numFeatures, embedding_dim, batch_input_shape = [batch_size, None]),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "    keras.layers.Dense(2, activation=tf.nn.sigmoid) #keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6039d3fb988e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rnn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-1a7ed5c305bd>\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(modelType)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodelType\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"rnn\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m#print('Accuracy >%.3f' % test_acc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m#print('Precision >%.3f' % precision)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "cross_validation(\"rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
