#data containers
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

#classifier models/tools
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import KFold # import KFold
from sklearn import metrics
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.feature_selection import SelectKBest #for feature selection
from sklearn.feature_selection import chi2

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM

#for getting data from csv
import csvWrite
import math


#function for feature selection
def removeFeatures(data_frame, feature_col_names): #data_frame: pd dataframe, feature_col_names: list
    '''remove unimportant features'''
    data_frame_tmp = data_frame
    feature_col_names_tmp = feature_col_names
    
    badFeatures = ['flaw', 'unsafe', 'vehicles', 'none', 'accepts', 'tiki', 'drivers', 'offset']
    for feature in badFeatures:
        if feature in data_frame_tmp.columns:
            data_frame_tmp.drop([feature], 1, inplace=True)
            feature_col_names_tmp.remove(feature)
    
    return data_frame_tmp, feature_col_names_tmp



print("Welcome to the SQL injection machine learning classifier")

#choose between implementing own files and using files already in FileSet folder
fileSetChoice = int(input("Use preset files (0) or input own files (1)?"))
if fileSetChoice == 0:
    featureSetChoice = int(input("Use bagofwords (0) or word2vec (1)?"))
    if featureSetChoice == 0:
        print("Rewrite fileInfo.csv? Contains feature information for file set")
        csvWrite.rewriteCSV()

        #get data frame of features
        csvDirectory = csvWrite.getCSVDirectory()
        data_frame = pd.read_csv(csvDirectory)

        #divide training and testing set
        feature_col_names, predicted_class_names = csvWrite.getFeatureColumns()

        #data frame filtering
        data_frame, feature_col_names = removeFeatures(data_frame, feature_col_names)
        
    elif featureSetChoice == 1:
        print("Please make sure you have a C compiler, like MinGW. If not, program will now fail.")
        assert gensim.models.doc2vec.FAST_VERSION > -1 #ensure fast performance. Need to download C compiler, like MinGW

        #get corpus
    else:
        print("Choice not understood.")
elif fileSetChoice == 1:
    pass
else:
    print("Choice not understood. Please restart.")
