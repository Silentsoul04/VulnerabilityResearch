from file import File
import os

#data containers
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

#classifier models/tools
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC  
from sklearn import tree
from sklearn.model_selection import KFold # import KFold
from sklearn import metrics
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import scale
from sklearn.metrics import mean_squared_error
from sklearn.feature_selection import SelectKBest #for feature selection
from sklearn.feature_selection import chi2

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import Embedding
from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D
from keras.layers import LSTM
from keras.layers import SimpleRNN

#for getting data from csv
import csvWrite
import fileRetriever
import bagOfWords

import math

#for word2vec
import gensim

#saving/loading models
import pickle

from sklearn.feature_extraction.text import TfidfVectorizer
LabeledSentence = gensim.models.doc2vec.LabeledSentence #before feeding token list to word2vec, they must be LabeledSentences

#function for feature selection
def removeFeatures(data_frame, feature_col_names): #data_frame: pd dataframe, feature_col_names: list
    '''remove unimportant features'''
    data_frame_tmp = data_frame
    feature_col_names_tmp = feature_col_names
    
    badFeatures = ['flaw', 'unsafe', 'vehicles', 'none', 'accepts', 'tiki', 'drivers', 'offset']
    for feature in badFeatures:
        if feature in data_frame_tmp.columns:
            data_frame_tmp.drop([feature], 1, inplace=True)
            feature_col_names_tmp.remove(feature)
    
    return data_frame_tmp, feature_col_names_tmp

def printBestFeatures(feature_col_names):
    '''print out top 10 features, given column names'''
    printFeatures = input('Print best features? (y/n) ')
    if printFeatures == 'y':        
        #apply SelectKBest class to extract top 10 best features
        bestfeatures = SelectKBest(score_func=chi2, k=10)
        fit = bestfeatures.fit(X,y)
        dfscores = pd.DataFrame(fit.scores_)
        dfcolumns = pd.DataFrame(feature_col_names)
        #concat two dataframes for better visualization 
        featureScores = pd.concat([dfcolumns,dfscores],axis=1)
        featureScores.columns = ['Specs','Score']  #naming the dataframe columns
        top10Features = featureScores.nlargest(10,'Score')  #10 best features
        print(top10Features)
    else:
        print("No features printed")

def reshape_y_nn(y):
    '''reshape y into two columns for neural networks'''

    #get a nonvulnerable column for y labels
    y_flipped = np.array(y, copy=True)
    for i in range(len(y_flipped)):
        if y_flipped[i][0] == 0:
            y_flipped[i][0] = 1
        elif y_flipped[i][0] == 1:
            y_flipped[i][0] = 0

    new_y = np.concatenate((y_flipped, y), axis=1) #0: nonvulner, 1: vulner
    return new_y

def chooseModelType(X, y):
    options = {
        0: "All Models",
        1: "Naive-Bayes",
        2: "Decision Tree",
        3: "Random Forest",
        4: "Support Vector Machine",
        5: "Logistic Regression",
        6: "Multilayer Perceptron",
        7: "Recurrent Neural Network",
        8: "Long Short-Term Memory",
        9: "Convolutional Neural Network"
    }
    
    print("Choose model type by entering number:")
    for num, modelType in options.items():
        print("{}: {}".format(num, modelType))
    
    user_input = int(input())
    while user_input < 0 or user_input >= len(options):
        print("Invalid number. Enter a valid number:")
        user_input = int(input())
    
    chosenModel = options[user_input]
    print("Training classifier...")
    if chosenModel == "All Models":
        cross_validation("nb", X, y)
        cross_validation("dt", X, y)
        cross_validation("rf", X, y)
        cross_validation("svm", X, y)
        cross_validation("lr", X, y)
        #reshape y for neural networks
        new_y = reshape_y_nn(y)     
        cross_validation("mlp", X, new_y)
        #reshape y for neural networks
        new_y = reshape_y_nn(y)     
        cross_validation("rnn", X, new_y)
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        cross_validation("lstm", X, new_y)
        #reshape y for neural networks
        new_y = reshape_y_nn(y)     
        cross_validation("cnn", X, new_y)
    elif chosenModel == "Naive-Bayes":
        cross_validation("nb", X, y)
    elif chosenModel == "Decision Tree":
        cross_validation("dt", X, y)
    elif chosenModel == "Random Forest":
        cross_validation("rf", X, y)
    elif chosenModel == "Support Vector Machine":   
        cross_validation("svm", X, y)
    elif chosenModel == "Logistic Regression":
        cross_validation("lr", X, y)
    elif chosenModel == "Multilayer Perceptron":
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        cross_validation("mlp", X, new_y)
    elif chosenModel == "Recurrent Neural Network":
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        cross_validation("rnn", X, new_y)
    elif chosenModel == "Long Short-Term Memory":
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        cross_validation("lstm", X, new_y)
    elif chosenModel == "Convolutional Neural Network":
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        cross_validation("cnn", X, new_y)
    else:
        print("Input not understood.")

    print("Training completed")

def printPredictions(predict_test, fileList):
    for i in range(len(predict_test)):
        if predict_test[i] == 1:
            print("Prediction %d: File at %s has a SQL injection vulnerability" % (i+1, fileList[i].dir))
        elif predict_test[i] == 0:
            #print("Prediction %d: File at %s does NOT have a SQL injection vulnerability" % (i+1, fileList[i].dir))
            pass
        else:
            print("Could not predict correctly. For debugging, predict_test[%d] was %f" % (i+1, predict_test[i]))
            
def chooseModelType_Test(X, y, fileList):
    options = {
        0: "All Models",
        1: "Naive-Bayes",
        2: "Decision Tree",
        3: "Random Forest",
        4: "Support Vector Machine",
        5: "Logistic Regression",
        6: "Multilayer Perceptron",
        7: "Recurrent Neural Network",
        8: "Long Short-Term Memory",
        9: "Convolutional Neural Network"
    }
    
    print("Choose model type by entering number:")
    for num, modelType in options.items():
        print("{}: {}".format(num, modelType))

    user_input = int(input())
    while user_input < 0 or user_input >= len(options):
        print("Invalid number. Enter a valid number:")
        user_input = int(input())

    chosenModel = options[user_input]

    if chosenModel == "All Models":
        '''cross_validation("nb", X, y)
        cross_validation("dt", X, y)
        cross_validation("rf", X, y)
        cross_validation("svm", X, y)
        cross_validation("lr", X, y)
        #reshape y for neural networks
        new_y = reshape_y_nn(y)     
        cross_validation("mlp", X, new_y)
        #reshape y for neural networks
        new_y = reshape_y_nn(y)     
        cross_validation("rnn", X, new_y)
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        cross_validation("lstm", X, new_y)
        #reshape y for neural networks
        new_y = reshape_y_nn(y)     
        cross_validation("cnn", X, new_y)'''
    elif chosenModel == "Naive-Bayes":
        #predict against model
        model = pickle.load(open("nb.sav", 'rb'))
        predict_test = model.predict(X)
        printPredictions(predict_test, fileList)
    elif chosenModel == "Decision Tree":
        #predict against model
        model = pickle.load(open("dt.sav", 'rb'))
        predict_test = model.predict(X)
        printPredictions(predict_test, fileList)
    elif chosenModel == "Random Forest":
        #predict against model
        model = pickle.load(open("rf.sav", 'rb'))
        predict_test = model.predict(X)
        printPredictions(predict_test, fileList)
    elif chosenModel == "Support Vector Machine":   
        #predict against model
        model = pickle.load(open("svm.sav", 'rb'))
        predict_test = model.predict(X)
        printPredictions(predict_test, fileList)
    elif chosenModel == "Logistic Regression":
        #predict against model
        model = pickle.load(open("lr.sav", 'rb'))
        predict_test = model.predict(X)
        printPredictions(predict_test, fileList)
    elif chosenModel == "Multilayer Perceptron":
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        #predict against model
        model = pickle.load(open("mlp.h5", 'rb'))
        predict_test = model.predict(X)
        printPredictions(predict_test, fileList)
    elif chosenModel == "Recurrent Neural Network":
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        #predict against model
        model = pickle.load(open("rnn.h5", 'rb'))
        predict_test = model.predict(X)
        printPredictions(predict_test, fileList)
    elif chosenModel == "Long Short-Term Memory":
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        #predict against model
        model = pickle.load(open("lstm.h5", 'rb'))
        predict_test = model.predict(X)
        printPredictions(predict_test, fileList)
    elif chosenModel == "Convolutional Neural Network":
        #reshape y for neural networks
        new_y = reshape_y_nn(y)
        #predict against model
        model = pickle.load(open("cnn.h5", 'rb'))
        predict_test = model.predict(X)
        printPredictions(predict_test, fileList)
    else:
        print("Input not understood.")
    


def cross_validation(modelType, X, y):
    '''Cross validation for various model types. modelType is a string for the model being used'''
    # prepare the k-fold cross-validation configuration
    n_folds = 10
    kfold = KFold(n_folds, True, 1) #n_splits, random_state, shuffle

    # cross validation estimation of performance
    scores, precisions, recalls, f1_scores, members = list(), list(), list(), list(), list()

    counter = 1
    for train_ix, test_ix in kfold.split(X):
        print("Cross validation iteration", counter)
        counter = counter + 1
        
        # select samples
        trainX, trainy = X[train_ix], y[train_ix]
        testX, testy = X[test_ix], y[test_ix]
        # evaluate model
        model, test_acc, precision, recall, f1_score = (0, 0, 0, 0, 0)

        print("trainX shape:", trainX.shape)
        print("testX shape:", testX.shape)
        print("trainy shape:", trainy.shape)
        print("testy shape:", testy.shape)
        
        if modelType == "nb":
            model, test_acc, precision, recall, f1_score = evaluate_model_nb(trainX, trainy, testX, testy, "bagOfWords")
        elif modelType == "dt":
            model, test_acc, precision, recall, f1_score = evaluate_model_dt(trainX, trainy, testX, testy, "bagOfWords")
        elif modelType == "rf":
            model, test_acc, precision, recall, f1_score = evaluate_model_rf(trainX, trainy, testX, testy, "bagOfWords")
            #print(model.feature_importances_)
        elif modelType == "svm":
            model, test_acc, precision, recall, f1_score = evaluate_model_svm(trainX, trainy, testX, testy, "bagOfWords")
        elif modelType == "lr":
            model, test_acc, precision, recall, f1_score = evaluate_model_lr(trainX, trainy, testX, testy, "bagOfWords")
        elif modelType == "mlp":
            model, test_acc, precision, recall, f1_score = evaluate_model_mlp(trainX, trainy, testX, testy, "bagOfWords")
        elif modelType == "rnn":
            # reshape input to be [samples, time steps, features]
            trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
            testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))
            
            model, test_acc, precision, recall, f1_score = evaluate_model_rnn(trainX, trainy, testX, testy, "bagOfWords")
        elif modelType == "lstm":
            # reshape input to be [samples, time steps, features]
            trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
            testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))
            
            model, test_acc, precision, recall, f1_score = evaluate_model_lstm(trainX, trainy, testX, testy, "bagOfWords")
        elif modelType == "cnn":
            # reshape input to be [samples, time steps, features]
            trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
            testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))
            
            model, test_acc, precision, recall, f1_score = evaluate_model_cnn(trainX, trainy, testX, testy, "bagOfWords")
            
        scores.append(test_acc)
        precisions.append(precision)
        recalls.append(recall)
        f1_scores.append(f1_score)
        members.append(model)

    # summarize expected performance
    print(modelType, "Performance")
    print('Estimated Accuracy: %.3f, Std Ddv: (%.3f)' % (np.mean(scores), np.std(scores)))
    print('Estimated Precision: %.3f, Std Ddv: (%.3f)' % (np.mean(precisions), np.std(precisions)))
    print('Estimated Recall: %.3f, Std Ddv: (%.3f)' % (np.mean(recalls), np.std(recalls)))
    print('Estimated F1-Score: %.3f, Std Ddv: (%.3f)' % (np.mean(f1_scores), np.std(f1_scores)))

def chooseModelType_word2vec(X, y):
    options = {
        0: "All Models",
        1: "Multilayer Perceptron",
        2: "Recurrent Neural Network",
        3: "Long Short-Term Memory",
        4: "Convolutional Neural Network"
    }
    
    print("Choose model type by entering number:")
    for num, modelType in options.items():
        print("{}: {}".format(num, modelType))
    
    user_input = int(input())
    while user_input < 0 or user_input >= len(options):
        print("Invalid number. Enter a valid number:")
        user_input = int(input())
    chosenModel = options[user_input]
    print("Training classifier...")
    if chosenModel == "All Models":    
        cross_validation_word2vec("mlp", X, y)
        cross_validation_word2vec("rnn", X, y)
        cross_validation_word2vec("lstm", X, y)
        cross_validation_word2vec("cnn", X, y)
    elif chosenModel == "Multilayer Perceptron":   
        cross_validation_word2vec("mlp", X, y)
    elif chosenModel == "Recurrent Neural Network":   
        cross_validation_word2vec("rnn", X, y)
    elif chosenModel == "Long Short-Term Memory":
        cross_validation_word2vec("lstm", X, y)
    elif chosenModel == "Convolutional Neural Network":   
        cross_validation_word2vec("cnn", X, y)
    else:
        print("Input not understood.")

    print("Training completed")

def cross_validation_word2vec(modelType, X, y):
    '''Cross validation for various model types. modelType is a string for the model being used'''
    # prepare the k-fold cross-validation configuration
    n_folds = 10
    kfold = KFold(n_folds, True, 1) #n_splits, random_state, shuffle

    # cross validation estimation of performance
    scores, precisions, recalls, f1_scores, members = list(), list(), list(), list(), list()

    counter = 1
    for train_ix, test_ix in kfold.split(X):
        print("Cross validation iteration", counter)
        counter = counter + 1
        
        # select samples
        trainX, trainy = X[train_ix], y[train_ix]
        testX, testy = X[test_ix], y[test_ix]

        #building word2vec model
        LabeledSentence = gensim.models.doc2vec.LabeledSentence #before feeding token list to word2vec, they must be LabeledSentences
            
        trainX = labelizeWords(trainX, 'TRAIN')
        testX = labelizeWords(testX, 'TEST')

        n_dim = 150

        word2vec_model = gensim.models.Word2Vec(size=n_dim, window=10, min_count=10, workers=10)
        word2vec_model.build_vocab([X.words for X in trainX])
        word2vec_model.train([X.words for X in trainX], total_examples=len(trainX), epochs=5)


        #BUILDING THE CLASSIFIER
        #building tf-idf vectorizer
        print('building tf-idf matrix ...')
        vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)
        matrix = vectorizer.fit_transform([X.words for X in trainX])
        tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))
        print('vocab size :', len(tfidf))

        #scale columns in X_train and X_test
        train_vecs_w2v = np.concatenate([buildWordVector(z, n_dim, word2vec_model, tfidf) for z in map(lambda x: x.words, trainX)])
        train_vecs_w2v = scale(train_vecs_w2v)

        test_vecs_w2v = np.concatenate([buildWordVector(z, n_dim, word2vec_model, tfidf) for z in map(lambda x: x.words, testX)])
        test_vecs_w2v = scale(test_vecs_w2v)

        print("train_vecs_w2v shape:", train_vecs_w2v.shape)
        print("test_vecs_w2v shape:", test_vecs_w2v.shape)
        print("trainy shape:", trainy.shape)
        print("testy shape:", testy.shape)
        
        # evaluate model
        model, test_acc, precision, recall, f1_score = (0, 0, 0, 0, 0)
        
        if modelType == "mlp":
            model, test_acc, precision, recall, f1_score = evaluate_model_mlp(train_vecs_w2v, trainy, test_vecs_w2v, testy, "word2vec")
        elif modelType == "rnn":
            # reshape input to be [samples, time steps, features]
            train_vecs_w2v = np.reshape(train_vecs_w2v, (train_vecs_w2v.shape[0], 1, train_vecs_w2v.shape[1]))
            test_vecs_w2v = np.reshape(test_vecs_w2v, (test_vecs_w2v.shape[0], 1, test_vecs_w2v.shape[1]))
            
            model, test_acc, precision, recall, f1_score = evaluate_model_rnn(train_vecs_w2v, trainy, test_vecs_w2v, testy, "word2vec")
        elif modelType == "lstm":
            # reshape input to be [samples, time steps, features]
            train_vecs_w2v = np.reshape(train_vecs_w2v, (train_vecs_w2v.shape[0], 1, train_vecs_w2v.shape[1]))
            test_vecs_w2v = np.reshape(test_vecs_w2v, (test_vecs_w2v.shape[0], 1, test_vecs_w2v.shape[1]))
            
            model, test_acc, precision, recall, f1_score = evaluate_model_lstm(train_vecs_w2v, trainy, test_vecs_w2v, testy, "word2vec")
        elif modelType == "cnn":
            # reshape input to be [samples, time steps, features]
            train_vecs_w2v = np.reshape(train_vecs_w2v, (train_vecs_w2v.shape[0], 1, train_vecs_w2v.shape[1]))
            test_vecs_w2v = np.reshape(test_vecs_w2v, (test_vecs_w2v.shape[0], 1, test_vecs_w2v.shape[1]))
            
            model, test_acc, precision, recall, f1_score = evaluate_model_cnn(train_vecs_w2v, trainy, test_vecs_w2v, testy, "word2vec")
        scores.append(test_acc)
        precisions.append(precision)
        recalls.append(recall)
        f1_scores.append(f1_score)
        members.append(model)

    # summarize expected performance
    print(modelType, "Performance")
    print('Estimated Accuracy: %.3f, Std Ddv: (%.3f)' % (np.mean(scores), np.std(scores)))
    print('Estimated Precision: %.3f, Std Ddv: (%.3f)' % (np.mean(precisions), np.std(precisions)))
    print('Estimated Recall: %.3f, Std Ddv: (%.3f)' % (np.mean(recalls), np.std(recalls)))
    print('Estimated F1-Score: %.3f, Std Ddv: (%.3f)' % (np.mean(f1_scores), np.std(f1_scores)))

def evaluate_model_nb(X_train, y_train, X_test, y_test, featureType):
    # define model
    #create Gaussian Naive Bayes model object and train it with the data
    model = GaussianNB()
    # fit model
    model.fit(X_train, y_train.ravel())

    # save model
    if featureType == "bagOfWords":
        filename = 'nb.sav'
        pickle.dump(model, open(filename, 'wb'))
    elif featureType == "word2vec":
        filename = 'nb_word2vec.sav'
        pickle.dump(model, open(filename, 'wb'))
    else:
        print("Classifier not saved")
    
    # evaluate the model
    #predict values using the testing data
    predict_test = model.predict(X_test)

    #Accuracy
    test_acc = metrics.accuracy_score(y_test, predict_test)
    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)
    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)
    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)
    
    return model, test_acc, precision, recall, f1_score

def evaluate_model_dt(X_train, y_train, X_test, y_test, featureType):
    # define model
    #create Decision Tree model object and train it with the data
    model = tree.DecisionTreeClassifier()
    # fit model
    model.fit(X_train, y_train.ravel())

    # save model
    if featureType == "bagOfWords":
        filename = 'dt.sav'
        pickle.dump(model, open(filename, 'wb'))
    elif featureType == "word2vec":
        filename = 'dt_word2vec.sav'
        pickle.dump(model, open(filename, 'wb'))
    else:
        print("Classifier not saved")
    
    # evaluate the model
    #predict values using the testing data
    predict_test = model.predict(X_test)

    #Accuracy
    test_acc = metrics.accuracy_score(y_test, predict_test)
    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)
    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)
    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)
    
    return model, test_acc, precision, recall, f1_score

def evaluate_model_rf(X_train, y_train, X_test, y_test, featureType):
    # define model
    #create Random Classifier model object and train it with the data
    model = RandomForestClassifier(random_state=42)
    # fit model
    #model.fit(X_train, y_train.ravel())
    model.fit(X_train, y_train)

    # save model
    if featureType == "bagOfWords":
        filename = 'rf.sav'
        pickle.dump(model, open(filename, 'wb'))
    elif featureType == "word2vec":
        filename = 'rf_word2vec.sav'
        pickle.dump(model, open(filename, 'wb'))
    else:
        print("Classifier not saved")
    
    # evaluate the model
    #predict values using the testing data
    predict_test = model.predict(X_test)

    #Accuracy
    test_acc = metrics.accuracy_score(y_test, predict_test)
    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)
    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)
    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)
    
    return model, test_acc, precision, recall, f1_score

def evaluate_model_svm(X_train, y_train, X_test, y_test, featureType):
    # define model
    #create Support Vector Machine model object and train it with the data
    model = SVC(kernel='linear')
    # fit model
    model.fit(X_train, y_train.ravel())

    # save model
    if featureType == "bagOfWords":
        filename = 'svm.sav'
        pickle.dump(model, open(filename, 'wb'))
    elif featureType == "word2vec":
        filename = 'svm_word2vec.sav'
        pickle.dump(model, open(filename, 'wb'))
    else:
        print("Classifier not saved")
    
    # evaluate the model
    #predict values using the testing data
    predict_test = model.predict(X_test)

    #Accuracy
    test_acc = metrics.accuracy_score(y_test, predict_test)
    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)
    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)
    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)
    
    return model, test_acc, precision, recall, f1_score

def evaluate_model_lr(X_train, y_train, X_test, y_test, featureType):
    # define model
    #create Logistic Regression model object and train it with the data
    model = LogisticRegression(C=0.7, random_state=42) #C is regularization hyperparameter
    # fit model
    model.fit(X_train, y_train.ravel())

    # save model
    if featureType == "bagOfWords":
        filename = 'lr.sav'
        pickle.dump(model, open(filename, 'wb'))
    elif featureType == "word2vec":
        filename = 'lr_word2vec.sav'
        pickle.dump(model, open(filename, 'wb'))
    else:
        print("Classifier not saved")
    
    # evaluate the model
    #predict values using the testing data
    predict_test = model.predict(X_test)

    #Accuracy
    test_acc = metrics.accuracy_score(y_test, predict_test)
    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)
    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)
    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)
    
    return model, test_acc, precision, recall, f1_score

def evaluate_model_mlp(X_train, y_train, X_test, y_test, featureType):
    # define model
    #create MLP model object and train it with the data
    model = keras.Sequential([
    #start with layer of input shape (anything, 17)
    #keras.layers.Dense(500, input_shape=(csvWrite.getNumFeatures(),), activation=tf.nn.relu),
    keras.layers.Dense(500, input_shape=(len(X_train[0]),), activation=tf.nn.relu), #len(X_train[0]) is the num of 
    keras.layers.Dense(16, activation=tf.nn.relu),
    keras.layers.Dense(2, activation=tf.nn.sigmoid) #keras.layers.Dense(1, activation=tf.nn.sigmoid)
])
    model.compile(optimizer='adam', 
              loss='binary_crossentropy',
              metrics=['accuracy'])
    
    # fit model
    history = model.fit(X_train, y_train, epochs=5)

    # save model
    '''filename = 'mlp.sav'
    pickle.dump(model, open(filename, 'wb'))'''
    if featureType == "bagOfWords":
        filename = 'mlp.h5'
        model.save(filename)
    elif featureType == "word2vec":
        filename = 'mlp_word2vec.h5'
        model.save(filename)
    else:
        print("Classifier not saved")
    
    # evaluate the model
    #predict values using the testing data
    predict_test = model.predict(X_test)

    predicted = np.argmax(predict_test, axis=1)
    
    report = metrics.classification_report(np.argmax(y_test, axis=1), predicted)
    #Accuracy
    test_loss, test_acc = model.evaluate(X_test, y_test)
    precision = metrics.precision_score(np.argmax(y_test, axis=1), predicted, pos_label = 1)
    recall = metrics.recall_score(np.argmax(y_test, axis=1), predicted, pos_label = 1)
    f1_score = metrics.f1_score(np.argmax(y_test, axis=1), predicted, pos_label = 1)
    
    return model, test_acc, precision, recall, f1_score

def evaluate_model_rnn(trainX, trainy, testX, testy, featureType):
    #dataDimensions = csvWrite.getNumFeatures()
    dataDimensions = len(trainX[0][0])
    
    # create and fit the RNN network
    model = Sequential()
    model.add(SimpleRNN(4, input_shape=(1, dataDimensions)))
    model.add(Dense(2)) #output layer, vulner or nonvulner
    model.compile(loss='mean_squared_error', optimizer='adam')
    model.fit(trainX, trainy, epochs=5, batch_size=1, verbose=2)

    # save model
    if featureType == "bagOfWords":
        filename = 'rnn.h5'
        model.save(filename)
    elif featureType == "word2vec":
        filename = 'rnn_word2vec.h5'
        model.save(filename)
    else:
        print("Classifier not saved")
    
    # evaluate the model
    #predict values using the testing data
    predict_test = model.predict(testX)
    
    predicted = np.argmax(predict_test, axis=1)

    #metrics
    report = metrics.classification_report(np.argmax(testy, axis=1), predicted)
    #test_loss, test_acc = model.evaluate(testX, testy)
    test_acc = metrics.accuracy_score(np.argmax(testy, axis=1), predicted)
    precision = metrics.precision_score(np.argmax(testy, axis=1), predicted, pos_label = 1)
    recall = metrics.recall_score(np.argmax(testy, axis=1), predicted, pos_label = 1)
    f1_score = metrics.f1_score(np.argmax(testy, axis=1), predicted, pos_label = 1)
    
    return model, test_acc, precision, recall, f1_score

def evaluate_model_lstm(trainX, trainy, testX, testy, featureType):
    #dataDimensions = csvWrite.getNumFeatures()
    dataDimensions = len(trainX[0][0])
    
    # create and fit the LSTM network
    model = Sequential()
    model.add(LSTM(4, input_shape=(1, dataDimensions)))
    model.add(Dense(2)) #output layer, vulner or nonvulner
    model.compile(loss='mean_squared_error', optimizer='adam')
    model.fit(trainX, trainy, epochs=5, batch_size=1, verbose=2)

    # save model
    if featureType == "bagOfWords":
        filename = 'lstm.h5'
        model.save(filename)
    elif featureType == "word2vec":
        filename = 'lstm_word2vec.h5'
        model.save(filename)
    else:
        print("Classifier not saved")
    
    # evaluate the model
    #predict values using the testing data
    predict_test = model.predict(testX)
    
    predicted = np.argmax(predict_test, axis=1)

    #metrics
    report = metrics.classification_report(np.argmax(testy, axis=1), predicted)
    test_acc = metrics.accuracy_score(np.argmax(testy, axis=1), predicted)
    precision = metrics.precision_score(np.argmax(testy, axis=1), predicted, pos_label = 1)
    recall = metrics.recall_score(np.argmax(testy, axis=1), predicted, pos_label = 1)
    f1_score = metrics.f1_score(np.argmax(testy, axis=1), predicted, pos_label = 1)
    
    return model, test_acc, precision, recall, f1_score

def evaluate_model_cnn(trainX, trainy, testX, testy, featureType):
    #dataDimensions = csvWrite.getNumFeatures()
    feature_number = len(trainX[0][0]) #count of features
    
    # create and fit the LSTM network
    model = Sequential()
    model.add(Conv1D(64, 1, activation='relu', input_shape=(None,feature_number)))
    model.add(Conv1D(64, 1, activation='relu'))
    model.add(MaxPooling1D(1))
    model.add(Conv1D(128, 1, activation='relu'))
    model.add(Conv1D(128, 1, activation='relu'))
    model.add(GlobalAveragePooling1D())
    model.add(Dropout(0.5))
    model.add(Dense(2, activation='sigmoid'))
    
    model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])
              
    model.fit(trainX, trainy, batch_size=16, epochs=5)

    # save model
    if featureType == "bagOfWords":
        filename = 'cnn.h5'
        model.save(filename)
    elif featureType == "word2vec":
        filename = 'cnn_word2vec.h5'
        model.save(filename)
    else:
        print("Classifier not saved")

    # evaluate the model
    #predict values using the testing data
    predict_test = model.predict(testX)
    
    predicted = np.argmax(predict_test, axis=1)

    #metrics
    report = metrics.classification_report(np.argmax(testy, axis=1), predicted)
    test_acc = metrics.accuracy_score(np.argmax(testy, axis=1), predicted)
    precision = metrics.precision_score(np.argmax(testy, axis=1), predicted, pos_label = 1)
    recall = metrics.recall_score(np.argmax(testy, axis=1), predicted, pos_label = 1)
    f1_score = metrics.f1_score(np.argmax(testy, axis=1), predicted, pos_label = 1)
    
    return model, test_acc, precision, recall, f1_score

def getCorpus():
    files = fileRetriever.getFileSet(2)
    corpus = []
    for i, file in enumerate(files):
        wordList = []
        with open(file.dir, "r", encoding="utf8") as f:
            text = f.read()
            text = bagOfWords.filterComments(text)
            wordList = gensim.utils.simple_preprocess(text) #maybe add min_len and max_len params
            corpus.append(wordList)

    return corpus
    
def labelizeWords(words, label_type):
    '''label corpus words'''
    labelized = []
    for i,v in enumerate(words):
        label = '%s_%s'%(label_type,i)
        labelized.append(LabeledSentence(v, [label]))
    return labelized

def buildWordVector(tokens, size, model, tfidf):
    '''given list of tokens, creates averaged vector. Used to turn X_train and X_test into vector list'''
    vec = np.zeros(size).reshape((1, size))
    count = 0.
    for word in tokens:
        try:
            vec += model[word].reshape((1, size)) * tfidf[word]
            count += 1.
        except KeyError: # handling the case where the token is not
                         # in the corpus. useful for testing.
            continue
    if count != 0:
        vec /= count

    #print("Word Vector Shape:")
    #print(vec.shape)
    return vec

def getUserFileDirectory():
    #FIXME: For single file, check if file has correct extension
    print("Enter a full directory or file path")
    print(r"ex: C:\VulnerabilityResearch\FileSet\Vulnerable\addressbook_family.inc") 
    userDir = input()
    assert os.path.exists(userDir), "I did not find the file at, "+str(userDir)
    return userDir

def printMenu():
    print("SQL Injection Classifier Menu")
    print("1. Retrain Classifier")
    print("2. Test File Set")
    print("3. Quit")



#PROGRAM START
print("Welcome to the SQL injection machine learning classifier!")
loop = True

while loop:
    printMenu()
    choice = int(input("Enter your choice: "))

    if choice == 1:
        print("Will retrain classifier")

        print("Rewrite fileInfo.csv? Contains feature information for file set ")
        csvWrite.rewriteCSV()

        #get data frame of features
        csvDirectory = csvWrite.getCSVDirectory()
        data_frame = pd.read_csv(csvDirectory)    
        
        featureSetChoice = int(input("Train bagofwords (0) or word2vec (1) implementation? "))
        if featureSetChoice == 0:

            #divide training and testing set
            feature_col_names, predicted_class_names = csvWrite.getFeatureColumns()
            print("feature col names before:", feature_col_names, "length:", len(feature_col_names))

            #data frame filtering
            data_frame, feature_col_names = removeFeatures(data_frame, feature_col_names)
            print("feature col names after:", feature_col_names, "length:", len(feature_col_names))

            #establish X and y data sets
            X = data_frame[feature_col_names].values # predictor feature columns (~500 x m)
            y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false)(1 x m)

            print("Number files in X:", len(X))
            print("Number features in X:", len(X[0]))

            #print most important features
            printBestFeatures(feature_col_names)

            print("Starting classifier training")
            chooseModelType(X, y)
        elif featureSetChoice == 1:
            print("Please make sure you have a C compiler, like MinGW. If not, program will now fail.")
            assert gensim.models.doc2vec.FAST_VERSION > -1 #ensure fast performance. Need to download C compiler, like MinGW

            #get corpus
            corpus = getCorpus()

            #establish X and y data sets
            X = np.array(corpus)
            _not_used, predicted_class_names = csvWrite.getFeatureColumns()
            y = data_frame[predicted_class_names].values

            #get a nonvulnerable column for y labels
            y_flipped = np.array(y, copy=True)
            for i in range(len(y_flipped)):
                if y_flipped[i][0] == 0:
                    y_flipped[i][0] = 1
                elif y_flipped[i][0] == 1:
                    y_flipped[i][0] = 0
                    
            y = np.concatenate((y_flipped, y), axis=1) #0: nonvulner, 1: vulner

            print("Starting classifier training")
            chooseModelType_word2vec(X, y)

    elif choice == 2:
        print("Using bag of words classifier")
        #FIXME: allow user to choose between bag of words and word2vec
        #FIXME: also allow users to choose between different classifier algorithms.
        #may need to pass alg as var and append onto csv file names
        #FIXME: also need to save word2vec and bag of words classifiers to separate files.
        #Right now, they both use evaluate_ functions, so need to pass in where it came from
        #FIXME: need to write word2vec to file. Need to be able to choose between them in extractFeatures in csvWrite
        #need to save to a different feature.pkl file
        userDir = getUserFileDirectory()
        if os.path.isfile(userDir):
            #may need to change userdir to use full file directory
            _unused, name = os.path.split(userDir)
            newFile = File(userDir, name)

            #write features to file
            csvWrite.extractFeatures([newFile])

            #get data frame of features
            csvDirectory = csvWrite.getCSVDirectory(getUserFile=True)
            data_frame = pd.read_csv(csvDirectory)

            feature_col_names, predicted_class_names = csvWrite.getFeatureColumns(getUserFile=True)
            print("feature col names before:", feature_col_names, "length:", len(feature_col_names))
            
            #data frame filtering
            data_frame, feature_col_names = removeFeatures(data_frame, feature_col_names)
        


            #reindex so data_frame does not have key error from empty columns (gives empty value for 
            #https://stackoverflow.com/questions/38462920/pandas-keyerror-value-not-in-index
            columns = predicted_class_names + feature_col_names
            data_frame = data_frame.reindex(columns=columns, fill_value=0)

            
            print("feature col names after:", feature_col_names, "length:", len(feature_col_names))
            #establish X and y data sets
            X = data_frame[feature_col_names].values # predictor feature columns (~500 x m)
            y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false)(1 x m)

            print("Length of X:", len(X[0]))

            #predict against model
            chooseModelType_Test(X, y, [newFile])
            '''model = pickle.load(open("nb.sav", 'rb'))
            predict_test = model.predict(X)
            test_acc = metrics.accuracy_score(y, predict_test)
            printPredictions(predict_test, [newFile])'''
            
        elif os.path.isdir(userDir):
            fileList = fileRetriever.getFiles(userDir)
            #for file in fileList:
            #    print(file.dir)

            #write features to file
            csvWrite.extractFeatures(fileList)

            #get data frame of features
            csvDirectory = csvWrite.getCSVDirectory(getUserFile=True)
            data_frame = pd.read_csv(csvDirectory)

            feature_col_names, predicted_class_names = csvWrite.getFeatureColumns(getUserFile=True)
            print("feature col names before:", feature_col_names, "length:", len(feature_col_names))
            
            #data frame filtering
            data_frame, feature_col_names = removeFeatures(data_frame, feature_col_names)
        


            #reindex so data_frame does not have key error from empty columns (gives empty value for 
            #https://stackoverflow.com/questions/38462920/pandas-keyerror-value-not-in-index
            columns = predicted_class_names + feature_col_names
            data_frame = data_frame.reindex(columns=columns, fill_value=0)

            
            print("feature col names after:", feature_col_names, "length:", len(feature_col_names))
            #establish X and y data sets
            X = data_frame[feature_col_names].values # predictor feature columns (~500 x m)
            y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false)(1 x m)

            print("Length of X:", len(X[0]))

            #predict against model
            model = pickle.load(open("nb.sav", 'rb'))
            predict_test = model.predict(X)
            test_acc = metrics.accuracy_score(y, predict_test)

            printPredictions(predict_test, fileList)
        else:
            print("Unable to determine if input was file or directory")

    elif choice == 3:
        print("Quitting program")
        loop = False
    else:
        print("Input not understood. Please try again")
