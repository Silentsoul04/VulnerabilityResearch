{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import csvWrite\n",
    "\n",
    "#do plotting inline\n",
    "%matplotlib inline\n",
    "\n",
    "#get directory\n",
    "csvDirectory = csvWrite.getCSVDirectory()\n",
    "\n",
    "data_frame = pd.read_csv(csvDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_col_names = csvWrite.getAllRowHeaders()\n",
    "feature_col_names = feature_col_names[2:] #all except name and vulnerable column\n",
    "predicted_class_names = ['Vulnerable']\n",
    "\n",
    "X = data_frame[feature_col_names].values # predictor feature columns (17 x m)\n",
    "y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false)(1 x m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(modelType):\n",
    "    #modelType is a string for the model being used\n",
    "    \n",
    "    # prepare the k-fold cross-validation configuration\n",
    "    n_folds = 10\n",
    "    kfold = KFold(n_folds, True, 1) #n_splits, random_state, shuffle\n",
    "\n",
    "    # cross validation estimation of performance\n",
    "    scores, precisions, recalls, f1_scores, members = list(), list(), list(), list(), list()\n",
    "\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        # select samples\n",
    "        trainX, trainy = X[train_ix], y[train_ix]\n",
    "        testX, testy = X[test_ix], y[test_ix]\n",
    "        # evaluate model\n",
    "        model, test_acc, precision, recall, f1_score = (0, 0, 0, 0, 0)\n",
    "        \n",
    "        if modelType == \"nb\":\n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_nb(trainX, trainy, testX, testy)\n",
    "        elif modelType == \"rf\":\n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_rf(trainX, trainy, testX, testy)\n",
    "        elif modelType == \"lr\":\n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_lr(trainX, trainy, testX, testy)\n",
    "        elif modelType == \"mlp\":\n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_mlp(trainX, trainy, testX, testy)\n",
    "        elif modelType == \"lstm\":\n",
    "            # reshape input to be [samples, time steps, features]\n",
    "            trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "            testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "            \n",
    "            model, test_acc, precision, recall, f1_score = evaluate_model_lstm(trainX, trainy, testX, testy)\n",
    "        #print('Accuracy >%.3f' % test_acc)\n",
    "        #print('Precision >%.3f' % precision)\n",
    "        #print('Recall >%.3f' % recall)\n",
    "        #print('F1-Scores >%.3f' % f1_score)\n",
    "        scores.append(test_acc)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "        members.append(model)\n",
    "\n",
    "    # summarize expected performance\n",
    "    print(modelType, \"Performance\")\n",
    "    print('Estimated Accuracy: %.3f, Std Ddv: (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "    print('Estimated Precision: %.3f, Std Ddv: (%.3f)' % (np.mean(precisions), np.std(precisions)))\n",
    "    print('Estimated Recall: %.3f, Std Ddv: (%.3f)' % (np.mean(recalls), np.std(recalls)))\n",
    "    print('Estimated F1-Score: %.3f, Std Ddv: (%.3f)' % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_nb(X_train, y_train, X_test, y_test):\n",
    "    # define model\n",
    "    #create Gaussian Naive Bayes model object and train it with the data\n",
    "    model = GaussianNB()\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(X_test)\n",
    "\n",
    "    #Accuracy\n",
    "    test_acc = metrics.accuracy_score(y_test, predict_test)\n",
    "    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)\n",
    "    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 10 Fold Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb Performance\n",
      "Estimated Accuracy: 0.998, Std Ddv: (0.001)\n",
      "Estimated Precision: 0.987, Std Ddv: (0.009)\n",
      "Estimated Recall: 0.997, Std Ddv: (0.007)\n",
      "Estimated F1-Score: 0.992, Std Ddv: (0.005)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(\"nb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_rf(X_train, y_train, X_test, y_test):\n",
    "    # define model\n",
    "    #create Random Classifier model object and train it with the data\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(X_test)\n",
    "\n",
    "    #Accuracy\n",
    "    test_acc = metrics.accuracy_score(y_test, predict_test)\n",
    "    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)\n",
    "    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 10 Fold Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf Performance\n",
      "Estimated Accuracy: 0.999, Std Ddv: (0.001)\n",
      "Estimated Precision: 0.992, Std Ddv: (0.006)\n",
      "Estimated Recall: 0.995, Std Ddv: (0.005)\n",
      "Estimated F1-Score: 0.994, Std Ddv: (0.002)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(\"rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_lr(X_train, y_train, X_test, y_test):\n",
    "    # define model\n",
    "    #create Logistic Regression model object and train it with the data\n",
    "    model = LogisticRegression(C=0.7, random_state=42) #C is regularization hyperparameter\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(X_test)\n",
    "\n",
    "    #Accuracy\n",
    "    test_acc = metrics.accuracy_score(y_test, predict_test)\n",
    "    precision = metrics.precision_score(y_test, predict_test, pos_label = 1)\n",
    "    recall = metrics.recall_score(y_test, predict_test, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(y_test, predict_test, pos_label = 1)\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr Performance\n",
      "Estimated Accuracy: 0.998, Std Ddv: (0.001)\n",
      "Estimated Precision: 0.990, Std Ddv: (0.007)\n",
      "Estimated Recall: 0.991, Std Ddv: (0.008)\n",
      "Estimated F1-Score: 0.990, Std Ddv: (0.004)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(\"lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide Training Data for Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame[feature_col_names].values # predictor feature columns (17 x m)\n",
    "y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false)(1 x m)\n",
    "#get a nonvulnerable column for y labels\n",
    "y_flipped = np.array(y, copy=True)\n",
    "for i in range(len(y_flipped)):\n",
    "    if y_flipped[i][0] == 0:\n",
    "        y_flipped[i][0] = 1\n",
    "    elif y_flipped[i][0] == 1:\n",
    "        y_flipped[i][0] = 0\n",
    "        \n",
    "y = np.concatenate((y_flipped, y), axis=1) #0: nonvulner, 1: vulner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_mlp(X_train, y_train, X_test, y_test):\n",
    "    # define model\n",
    "    #create MLP model object and train it with the data\n",
    "    model = keras.Sequential([\n",
    "    #start with layer of input shape (anything, 17)\n",
    "    keras.layers.Dense(500, input_shape=(csvWrite.getNumFeatures(),), activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.sigmoid) #keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    # fit model\n",
    "    history = model.fit(X_train, y_train, epochs=5)\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(X_test)\n",
    "\n",
    "    predicted = np.argmax(predict_test, axis=1)\n",
    "    \n",
    "    #print(np.argmax(y_test, axis=1).shape)\n",
    "    #print(np.argmax(y_test, axis=1))\n",
    "    #print(predict_test.shape)\n",
    "    #print(predict_test)\n",
    "    \n",
    "    #import the performance metrics library\n",
    "    report = metrics.classification_report(np.argmax(y_test, axis=1), predicted)\n",
    "    #Accuracy\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    precision = metrics.precision_score(np.argmax(y_test, axis=1), predicted, pos_label = 1)\n",
    "    recall = metrics.recall_score(np.argmax(y_test, axis=1), predicted, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(np.argmax(y_test, axis=1), predicted, pos_label = 1)\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ga6198\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "8738/8738 [==============================] - 1s 109us/sample - loss: 0.1319 - acc: 0.9527\n",
      "Epoch 2/5\n",
      "8738/8738 [==============================] - 1s 69us/sample - loss: 0.0081 - acc: 0.9987\n",
      "Epoch 3/5\n",
      "8738/8738 [==============================] - 1s 72us/sample - loss: 0.0034 - acc: 0.9991\n",
      "Epoch 4/5\n",
      "8738/8738 [==============================] - 1s 70us/sample - loss: 0.0017 - acc: 0.9994\n",
      "Epoch 5/5\n",
      "8738/8738 [==============================] - 1s 68us/sample - loss: 7.3857e-04 - acc: 0.9998\n",
      "971/971 [==============================] - 0s 127us/sample - loss: 0.0029 - acc: 0.9990\n",
      "Epoch 1/5\n",
      "8738/8738 [==============================] - 1s 100us/sample - loss: 0.1441 - acc: 0.9506\n",
      "Epoch 2/5\n",
      "8738/8738 [==============================] - 1s 70us/sample - loss: 0.0079 - acc: 0.9991\n",
      "Epoch 3/5\n",
      "8738/8738 [==============================] - 1s 69us/sample - loss: 0.0026 - acc: 0.9995\n",
      "Epoch 4/5\n",
      "8738/8738 [==============================] - 1s 70us/sample - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 5/5\n",
      "8738/8738 [==============================] - 1s 72us/sample - loss: 6.3957e-04 - acc: 0.9998\n",
      "971/971 [==============================] - 0s 137us/sample - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 1/5\n",
      "8738/8738 [==============================] - 1s 103us/sample - loss: 0.1378 - acc: 0.9519\n",
      "Epoch 2/5\n",
      "8738/8738 [==============================] - 1s 80us/sample - loss: 0.0087 - acc: 0.9987\n",
      "Epoch 3/5\n",
      "8738/8738 [==============================] - 1s 74us/sample - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 4/5\n",
      "8738/8738 [==============================] - 1s 79us/sample - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 5/5\n",
      "8738/8738 [==============================] - 1s 77us/sample - loss: 9.1268e-04 - acc: 0.9997\n",
      "971/971 [==============================] - 0s 145us/sample - loss: 3.9646e-04 - acc: 1.0000\n",
      "Epoch 1/5\n",
      "8738/8738 [==============================] - 1s 119us/sample - loss: 0.1544 - acc: 0.9491\n",
      "Epoch 2/5\n",
      "8738/8738 [==============================] - 1s 81us/sample - loss: 0.0085 - acc: 0.9991\n",
      "Epoch 3/5\n",
      "8738/8738 [==============================] - 1s 76us/sample - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 4/5\n",
      "8738/8738 [==============================] - 1s 77us/sample - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "8738/8738 [==============================] - 1s 75us/sample - loss: 7.0882e-04 - acc: 0.9999\n",
      "971/971 [==============================] - 0s 147us/sample - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 1/5\n",
      "8738/8738 [==============================] - 1s 114us/sample - loss: 0.1514 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "8738/8738 [==============================] - 1s 78us/sample - loss: 0.0097 - acc: 0.9986\n",
      "Epoch 3/5\n",
      "8738/8738 [==============================] - 1s 79us/sample - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 4/5\n",
      "8738/8738 [==============================] - 1s 78us/sample - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 5/5\n",
      "8738/8738 [==============================] - 1s 78us/sample - loss: 9.6234e-04 - acc: 0.9998\n",
      "971/971 [==============================] - 0s 158us/sample - loss: 0.0136 - acc: 0.9979\n",
      "Epoch 1/5\n",
      "8738/8738 [==============================] - 1s 110us/sample - loss: 0.1460 - acc: 0.9504\n",
      "Epoch 2/5\n",
      "8738/8738 [==============================] - 1s 85us/sample - loss: 0.0087 - acc: 0.9990\n",
      "Epoch 3/5\n",
      "8738/8738 [==============================] - 1s 79us/sample - loss: 0.0029 - acc: 0.9994\n",
      "Epoch 4/5\n",
      "8738/8738 [==============================] - 1s 87us/sample - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "8738/8738 [==============================] - 1s 91us/sample - loss: 8.9414e-04 - acc: 0.9999\n",
      "971/971 [==============================] - 0s 171us/sample - loss: 0.0081 - acc: 0.9974\n",
      "Epoch 1/5\n",
      "8738/8738 [==============================] - 1s 111us/sample - loss: 0.1620 - acc: 0.9404\n",
      "Epoch 2/5\n",
      "8738/8738 [==============================] - 1s 79us/sample - loss: 0.0107 - acc: 0.9989\n",
      "Epoch 3/5\n",
      "8738/8738 [==============================] - 1s 76us/sample - loss: 0.0033 - acc: 0.9995\n",
      "Epoch 4/5\n",
      "8738/8738 [==============================] - 1s 77us/sample - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "8738/8738 [==============================] - 1s 81us/sample - loss: 7.8595e-04 - acc: 0.9998\n",
      "971/971 [==============================] - 0s 165us/sample - loss: 0.0061 - acc: 0.9990\n",
      "Epoch 1/5\n",
      "8738/8738 [==============================] - 1s 122us/sample - loss: 0.1452 - acc: 0.9513\n",
      "Epoch 2/5\n",
      "8738/8738 [==============================] - 1s 84us/sample - loss: 0.0083 - acc: 0.9990\n",
      "Epoch 3/5\n",
      "8738/8738 [==============================] - 1s 78us/sample - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 4/5\n",
      "8738/8738 [==============================] - 1s 77us/sample - loss: 0.0010 - acc: 0.9995\n",
      "Epoch 5/5\n",
      "8738/8738 [==============================] - 1s 80us/sample - loss: 2.6629e-04 - acc: 1.0000\n",
      "971/971 [==============================] - 0s 167us/sample - loss: 0.0086 - acc: 0.9990\n",
      "Epoch 1/5\n",
      "8738/8738 [==============================] - 1s 118us/sample - loss: 0.1209 - acc: 0.9606\n",
      "Epoch 2/5\n",
      "8738/8738 [==============================] - 1s 96us/sample - loss: 0.0073 - acc: 0.9993\n",
      "Epoch 3/5\n",
      "8738/8738 [==============================] - 1s 82us/sample - loss: 0.0026 - acc: 0.9995\n",
      "Epoch 4/5\n",
      "8738/8738 [==============================] - 1s 90us/sample - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 5/5\n",
      "8738/8738 [==============================] - 1s 87us/sample - loss: 7.4059e-04 - acc: 0.9998\n",
      "971/971 [==============================] - 0s 173us/sample - loss: 0.0080 - acc: 0.9985\n",
      "Epoch 1/5\n",
      "8739/8739 [==============================] - 1s 121us/sample - loss: 0.1518 - acc: 0.9451\n",
      "Epoch 2/5\n",
      "8739/8739 [==============================] - 1s 83us/sample - loss: 0.0067 - acc: 0.9993\n",
      "Epoch 3/5\n",
      "8739/8739 [==============================] - 1s 80us/sample - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 4/5\n",
      "8739/8739 [==============================] - 1s 79us/sample - loss: 8.5731e-04 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "8739/8739 [==============================] - 1s 82us/sample - loss: 2.4417e-04 - acc: 1.0000\n",
      "970/970 [==============================] - 0s 166us/sample - loss: 0.0051 - acc: 0.9979\n",
      "mlp Performance\n",
      "Estimated Accuracy: 0.999, Std Ddv: (0.001)\n",
      "Estimated Precision: 0.992, Std Ddv: (0.006)\n",
      "Estimated Recall: 0.996, Std Ddv: (0.006)\n",
      "Estimated F1-Score: 0.994, Std Ddv: (0.003)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(\"mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_lstm(trainX, trainy, testX, testy):\n",
    "    dataDimensions = csvWrite.getNumFeatures()\n",
    "    \n",
    "    # create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(1, dataDimensions)))\n",
    "    model.add(Dense(2)) #output layer, vulner or nonvulner\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainy, epochs=5, batch_size=1, verbose=2)\n",
    "    \n",
    "    # evaluate the model\n",
    "    #predict values using the testing data\n",
    "    predict_test = model.predict(testX)\n",
    "    \n",
    "    predicted = np.argmax(predict_test, axis=1)\n",
    "\n",
    "    #metrics\n",
    "    report = metrics.classification_report(np.argmax(testy, axis=1), predicted)\n",
    "    #test_loss, test_acc = model.evaluate(testX, testy)\n",
    "    test_acc = metrics.accuracy_score(np.argmax(testy, axis=1), predicted)\n",
    "    precision = metrics.precision_score(np.argmax(testy, axis=1), predicted, pos_label = 1)\n",
    "    recall = metrics.recall_score(np.argmax(testy, axis=1), predicted, pos_label = 1)\n",
    "    f1_score = metrics.f1_score(np.argmax(testy, axis=1), predicted, pos_label = 1)\n",
    "    \n",
    "    return model, test_acc, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 13s - loss: 0.0197\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.0015\n",
      "Epoch 3/5\n",
      " - 13s - loss: 8.9030e-04\n",
      "Epoch 4/5\n",
      " - 13s - loss: 6.7428e-04\n",
      "Epoch 5/5\n",
      " - 13s - loss: 5.8089e-04\n",
      "Epoch 1/5\n",
      " - 14s - loss: 0.0202\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.0013\n",
      "Epoch 3/5\n",
      " - 13s - loss: 8.8576e-04\n",
      "Epoch 4/5\n",
      " - 13s - loss: 6.6641e-04\n",
      "Epoch 5/5\n",
      " - 13s - loss: 5.0970e-04\n",
      "Epoch 1/5\n",
      " - 14s - loss: 0.0203\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.0017\n",
      "Epoch 3/5\n",
      " - 14s - loss: 0.0011\n",
      "Epoch 4/5\n",
      " - 14s - loss: 7.8733e-04\n",
      "Epoch 5/5\n",
      " - 14s - loss: 5.8017e-04\n",
      "Epoch 1/5\n",
      " - 15s - loss: 0.0213\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.0015\n",
      "Epoch 3/5\n",
      " - 13s - loss: 8.9789e-04\n",
      "Epoch 4/5\n",
      " - 13s - loss: 6.2819e-04\n",
      "Epoch 5/5\n",
      " - 13s - loss: 5.1458e-04\n",
      "Epoch 1/5\n",
      " - 14s - loss: 0.0214\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.0014\n",
      "Epoch 3/5\n",
      " - 13s - loss: 9.3289e-04\n",
      "Epoch 4/5\n",
      " - 13s - loss: 6.3463e-04\n",
      "Epoch 5/5\n",
      " - 13s - loss: 5.5394e-04\n",
      "Epoch 1/5\n",
      " - 14s - loss: 0.0225\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.0016\n",
      "Epoch 3/5\n",
      " - 13s - loss: 8.6047e-04\n",
      "Epoch 4/5\n",
      " - 13s - loss: 7.0943e-04\n",
      "Epoch 5/5\n",
      " - 13s - loss: 5.8274e-04\n",
      "Epoch 1/5\n",
      " - 14s - loss: 0.0210\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.0014\n",
      "Epoch 3/5\n",
      " - 13s - loss: 7.9225e-04\n",
      "Epoch 4/5\n",
      " - 13s - loss: 6.8694e-04\n",
      "Epoch 5/5\n",
      " - 13s - loss: 4.6552e-04\n",
      "Epoch 1/5\n",
      " - 15s - loss: 0.0184\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.0014\n",
      "Epoch 3/5\n",
      " - 13s - loss: 7.9516e-04\n",
      "Epoch 4/5\n",
      " - 14s - loss: 6.5242e-04\n",
      "Epoch 5/5\n",
      " - 14s - loss: 4.8888e-04\n",
      "Epoch 1/5\n",
      " - 15s - loss: 0.0212\n",
      "Epoch 2/5\n",
      " - 14s - loss: 0.0015\n",
      "Epoch 3/5\n",
      " - 14s - loss: 9.0680e-04\n",
      "Epoch 4/5\n",
      " - 14s - loss: 7.4964e-04\n",
      "Epoch 5/5\n",
      " - 14s - loss: 6.1159e-04\n",
      "Epoch 1/5\n",
      " - 15s - loss: 0.0197\n",
      "Epoch 2/5\n",
      " - 14s - loss: 0.0013\n",
      "Epoch 3/5\n",
      " - 14s - loss: 8.4670e-04\n",
      "Epoch 4/5\n",
      " - 14s - loss: 6.1705e-04\n",
      "Epoch 5/5\n",
      " - 14s - loss: 4.7305e-04\n",
      "lstm Performance\n",
      "Estimated Accuracy: 0.999, Std Ddv: (0.001)\n",
      "Estimated Precision: 0.991, Std Ddv: (0.005)\n",
      "Estimated Recall: 0.997, Std Ddv: (0.004)\n",
      "Estimated F1-Score: 0.994, Std Ddv: (0.003)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(\"lstm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
