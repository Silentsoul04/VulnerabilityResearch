import fileRetriever
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk

'''def getBagOfWords(fileSetChoice):
    files = fileRetriever.getFileSet(fileSetChoice)
    textList = [] #list of text for all files
    for file in files:
        with open(file.dir, "r") as f:
            lines = list(f) # store all lines together
            text = "".join(lines) # join lines into single string
            textList.append(text)

    #initialize vectorizer
    vectorizer = CountVectorizer()
    X = vectorizer.fit_transform(textList) #tokenize and count words
    print(X.toarray())
    return X.toarray()'''

def tokenizeCode(text):
    tokens = nltk.word_tokenize(text)
    return tokens

def getTextList(fileList):
    textList = []
    for file in fileList:
        with open(file.dir, "r", encoding="utf8") as f:
            lines = list(f) # store all lines together
            text = "".join(lines) # join lines into single string
            textList.append(text)

    #print(textList)
    return textList

def getBagOfWords(fileList): #get bag of words w/ countVectorizer
    textList = getTextList(fileList)

    #print("Type of the textList", type(textList))

    #initialize vectorizer
    #vectorizer = CountVectorizer(tokenizer=tokenizeCode)
    vectorizer = CountVectorizer(min_df=5, max_features=500)
    X = vectorizer.fit_transform(textList) #tokenize and count words
    featureNames = vectorizer.get_feature_names()
    featureList = X.toarray()
    print(featureList)
    print("Shape", X.shape)
    print(featureNames)
    return featureNames, featureList #featureNames: [], featureList: [[]] 

def getBagOfWords_tdidf(fileList): #get bag of words w/ tdidfVectorizer
    textList = getTextList(fileList)

    #initialize vectorizer
    vectorizer = TfidfVectorizer(min_df=5, max_features=500) #features w/ count of 5, top 500 features
    X = vectorizer.fit_transform(textList) #tokenize and count words
    featureNames = vectorizer.get_feature_names()
    featureList = X.toarray()
    print(featureList)
    print("Shape", X.shape)
    print(featureNames)
    return featureNames, featureList #featureNames: [], featureList: [[]]

if __name__ == "__main__":
    files = fileRetriever.getFileSet(0)
    #getBagOfWords(files)
    getBagOfWords_tdidf(files)
