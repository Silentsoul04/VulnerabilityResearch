Cannot input text to deep learning, but you can input numbers.
Encoding changes text to numbers.

ex w/ one hot encoding. 
thank you
love you

unique words: [thank, you, love]
thank encoding: [1, 0, 0]
you: [0, 1, 0]
love: [0, 0, 1]

one hot encoding doesn't have similarity though. Everything has same distance to each other.

embedding is dense vector w/ similarity.
Word2vec is word embedding. Similarity comes from neighbor words.

Word2Vec depp learning model, input and target:
input: word one hot encoding
target: neighbor one hot encoding

3 layers: input (one hot encoding), hidden (linear neuron), output (softmax, same num nodes as input). Output has cross entropy to target.

hidden layer is like a lookup table.